# Credit Report Highlighter - Complete System Architecture & Flow

## üèóÔ∏è System Components

### 1. **Frontend (React/Vite)**
- **Port**: 5173
- **Main File**: `src/components/generated/CreditReportAnalyzerApp.tsx`
- **Purpose**: User interface for uploading PDFs and displaying results

### 2. **PyMuPDF Server (Python/Flask)**
- **Port**: 5175
- **Main File**: `pymupdf_highlight_server.py`
- **Purpose**: PDF manipulation - highlighting, text extraction, image conversion

### 3. **GPT-5 Vision Service (TypeScript)**
- **Main File**: `src/services/gpt5VisionAnalyzer.ts`
- **Purpose**: Coordinates AI analysis and manages the flow

---

## üìä Complete Process Flow (Step by Step)

### **Phase 1: User Upload & Initial Setup**

```
User clicks "Upload PDF" ‚Üí Browser
                ‚Üì
File stored in React state (CreditReportAnalyzerApp.tsx)
                ‚Üì
PDF displayed using PDF.js library (left panel)
```

### **Phase 2: User Clicks Analysis Button**

When user clicks "Full Analysis (GPT-5)" or any quick action button:

```
1. CreditReportAnalyzerApp.tsx ‚Üí handleAnalyze()
                ‚Üì
2. Calls gpt5VisionAnalyzer.analyzeWithVision()
```

### **Phase 3: Multi-Pass Analysis Process**

#### **Step 3.1: Text Extraction (Optional)**
```
gpt5VisionAnalyzer.ts ‚Üí extractTextWithCoordinates()
                ‚Üì
HTTP POST ‚Üí localhost:5175/extract-text-coordinates
                ‚Üì
pymupdf_highlight_server.py processes PDF
                ‚Üì
Returns: Text tokens with exact coordinates
```

#### **Step 3.2: Image Extraction**
```
gpt5VisionAnalyzer.ts ‚Üí extractPDFImages()
                ‚Üì
HTTP POST ‚Üí localhost:5175/convert-to-images
                ‚Üì
pymupdf_highlight_server.py converts PDF pages to PNG
                ‚Üì
Returns: Base64 encoded images (300 DPI)
```

#### **Step 3.3: Create Chunks**
```
gpt5VisionAnalyzer.ts ‚Üí createDynamicChunks()
                ‚Üì
Groups pages based on token budget (8000 tokens)
                ‚Üì
Creates chunks with images + text
```

#### **Step 3.4: Vision Analysis (THE CRITICAL PART)**
```
For each chunk:
    gpt5VisionAnalyzer.ts ‚Üí processChunkWithVision()
                    ‚Üì
    Creates prompt with:
    - Text content
    - Base64 images
    - Instructions to find issues
                    ‚Üì
    HTTP POST ‚Üí api.openai.com/v1/chat/completions
                    ‚Üì
    GPT-5 analyzes images
                    ‚Üì
    Returns JSON with issues and coordinates
```

#### **Step 3.5: Parse & Validate Results**
```
gpt5VisionAnalyzer.ts ‚Üí parseVisionResponse()
                ‚Üì
Validates coordinates exist
                ‚Üì
Converts pixel coordinates ‚Üí PDF points (72 DPI)
                ‚Üì
Filters invalid issues
```

### **Phase 4: Creating Highlights**

```
gpt5VisionAnalyzer.ts ‚Üí combineChunkResults()
                ‚Üì
All issues combined into single array
                ‚Üì
HTTP POST ‚Üí localhost:5175/highlight-pdf
                ‚Üì
pymupdf_highlight_server.py ‚Üí highlight_pdf()
                ‚Üì
For each issue:
    - Creates yellow rectangle at coordinates
    - Adds to PDF as annotation
                ‚Üì
Returns: Modified PDF with highlights
```

### **Phase 5: Display Results**

```
Backend returns highlighted PDF
                ‚Üì
CreditReportAnalyzerApp.tsx updates state
                ‚Üì
Right panel shows highlighted PDF
                ‚Üì
"Download Highlighted PDF" button appears
```

---

## üî¥ WHERE THINGS ARE BREAKING

### **Problem 1: GPT-5 Finding Too Few Issues**
- **Location**: `gpt5VisionAnalyzer.ts` ‚Üí `createVisionAnalysisPrompt()`
- **Issue**: Prompt is too restrictive, only looking for missing data
- **File**: Lines 469-533

### **Problem 2: Coordinates Not Working**
- **Location**: `gpt5VisionAnalyzer.ts` ‚Üí `combineChunkResults()`
- **Issue**: Pixel to points conversion may be wrong
- **File**: Lines 579-597

### **Problem 3: Validation Too Strict**
- **Location**: `gpt5VisionAnalyzer.ts` ‚Üí Lines 599-606
- **Issue**: Rejecting valid issues due to coordinate validation

---

## üìÅ Key Files & Their Roles

### **Frontend Files:**
1. `src/components/generated/CreditReportAnalyzerApp.tsx`
   - Main UI component
   - Handles file upload
   - Triggers analysis
   - Displays results

2. `src/services/gpt5VisionAnalyzer.ts`
   - Orchestrates entire analysis
   - Calls PyMuPDF server
   - Calls GPT-5 API
   - Processes results

### **Backend Files:**
1. `pymupdf_highlight_server.py`
   - `/health` - Health check
   - `/convert-to-images` - PDF ‚Üí PNG conversion
   - `/extract-text-coordinates` - Text extraction
   - `/highlight-pdf` - Apply highlights

### **Test Scripts:**
1. `test-real-gpt5-vision.py` - Original test
2. `test-improved-gpt5-vision.py` - Multi-pass test
3. `test-iterative-gpt5-vision.py` - One issue type at a time
4. `hybrid-pattern-vision-analyzer.py` - Combined pattern + vision approach

---

## üîÑ API Call Sequence

```
1. Frontend ‚Üí PyMuPDF: Extract text (optional)
2. Frontend ‚Üí PyMuPDF: Convert to images
3. Frontend ‚Üí OpenAI: Analyze images with GPT-5
4. Frontend ‚Üí PyMuPDF: Apply highlights
5. Frontend displays result
```

---

## üêõ Current Issues & Solutions

### **Issue 1: Only 4 issues found**
**Cause**: GPT-5 prompt too restrictive
**Solution**: Broadened prompt in lines 473-533

### **Issue 2: Highlights not showing**
**Possible Causes**:
1. Coordinates are in wrong format
2. Validation rejecting valid issues
3. PyMuPDF not receiving correct data

### **Issue 3: Too many console logs**
**Cause**: Processing each page individually
**Solution**: Added summary logging

---

## üîç How to Debug

1. **Check GPT-5 Response**:
   - Look for "GPT-5 Vision API response received" in console
   - Check if JSON contains coordinates

2. **Check Coordinate Format**:
   - Should be: `{x: number, y: number, width: number, height: number}`
   - Must be in PDF points (72 DPI), not pixels

3. **Check PyMuPDF Server**:
   - Look for `/highlight-pdf` requests
   - Check if returning 200 status

4. **Check Final Issues Array**:
   - Before sending to PyMuPDF
   - Must have valid coordinates for each issue

---

## üìù Quick Test

To test if highlighting works at all:
```python
python3 test-improved-gpt5-vision.py
```

This will create test outputs in `improved_test_outputs/` folder.

---

## üéØ Summary

The flow is:
1. **Upload PDF** ‚Üí Frontend
2. **Convert to images** ‚Üí PyMuPDF Server
3. **Analyze images** ‚Üí GPT-5 Vision API
4. **Get coordinates** ‚Üí From GPT-5 response
5. **Apply highlights** ‚Üí PyMuPDF Server
6. **Show result** ‚Üí Frontend

The break is likely at step 4 (not getting good coordinates) or step 5 (coordinate format wrong for PyMuPDF).

---

## üÜï Analysis Strategies

### **1. Vision-Only Approach** (Original)
- **File**: `test-real-gpt5-vision.py`
- **Method**: GPT-5 analyzes page images
- **Pros**: Can detect visual anomalies
- **Cons**: May miss text-based patterns, expensive API calls

### **2. Iterative Vision Approach** (Improved)
- **File**: `test-iterative-gpt5-vision.py`
- **Method**: Scans for one issue type at a time
- **Pros**: More focused, better accuracy per issue type
- **Cons**: Multiple API calls, slower

### **3. Pattern-Based Approach** (Traditional)
- **Method**: Regex patterns on extracted text
- **Pros**: Fast, deterministic, no API costs
- **Cons**: Can't detect visual issues, rigid patterns

### **4. Hybrid Approach** (Best of Both)
- **File**: `hybrid-pattern-vision-analyzer.py`
- **Method**: Combines pattern matching + GPT-5 vision
- **Flow**:
  ```
  Phase 1: Pattern Detection (Fast)
      ‚Üì
  Extract text with PyMuPDF
      ‚Üì
  Apply regex patterns for known errors
      ‚Üì
  Get exact text positions
      ‚Üì
  Phase 2: Vision Enhancement (Smart)
      ‚Üì
  Convert pages to images
      ‚Üì
  GPT-5 finds visual/complex issues
      ‚Üì
  Phase 3: Merge & Deduplicate
      ‚Üì
  Combine results from both methods
      ‚Üì
  Remove duplicates based on location
  ```

#### **Hybrid Approach Patterns:**
```python
ERROR_PATTERNS = {
    ErrorType.COLLECTION: [
        r'\bCOLLECTION\b',
        r'PORTFOLIO RECOVERY',
        r'CAVALRY PORTFOLIO',
    ],
    ErrorType.CHARGE_OFF: [
        r'CHARGE[\s\-_]?OFF',
        r'Charged Off',
    ],
    ErrorType.LATE_PAYMENT: [
        r'\b(30|60|90|120|150|180)\s*Days?\s*Past\s*Due',
    ],
    ErrorType.TRUNCATED_ACCOUNT: [
        r'[X\*]{4,}[\s\-]?\d{4}',  # XXXX1234 - FCRA violation
    ]
}
```

#### **Why Hybrid is Better:**
1. **Speed**: Pattern matching finds known errors instantly
2. **Coverage**: GPT-5 catches what patterns miss
3. **Cost**: Fewer API calls (only for complex issues)
4. **Accuracy**: Two independent methods validate each other
5. **FCRA Compliance**: Specific patterns for truncated accounts