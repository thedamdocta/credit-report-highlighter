# Credit Report Highlighter - Complete System Architecture & Flow

## ğŸ—ï¸ System Components

### 1. **Frontend (React/Vite)**
- **Port**: 5173
- **Main File**: `src/components/generated/CreditReportAnalyzerApp.tsx`
- **Purpose**: User interface for uploading PDFs and displaying results

### 2. **PyMuPDF Server (Python/Flask)**
- **Port**: 5175
- **Main File**: `pymupdf_highlight_server.py`
- **Purpose**: PDF manipulation - highlighting, text extraction, image conversion

### 3. **GPT-5 Vision Service (TypeScript)**
- **Main File**: `src/services/gpt5VisionAnalyzer.ts`
- **Purpose**: Coordinates AI analysis and manages the flow

---

## ğŸ“Š Complete Process Flow (Step by Step)

### **Phase 1: User Upload & Initial Setup**

```
User clicks "Upload PDF" â†’ Browser
                â†“
File stored in React state (CreditReportAnalyzerApp.tsx)
                â†“
PDF displayed using PDF.js library (left panel)
```

### **Phase 2: User Clicks Analysis Button**

When user clicks "Full Analysis (GPT-5)" or any quick action button:

```
1. CreditReportAnalyzerApp.tsx â†’ handleAnalyze()
                â†“
2. Calls gpt5VisionAnalyzer.analyzeWithVision()
```

### **Phase 3: Multi-Pass Analysis Process**

#### **Step 3.1: Text Extraction (Optional)**
```
gpt5VisionAnalyzer.ts â†’ extractTextWithCoordinates()
                â†“
HTTP POST â†’ localhost:5175/extract-text-coordinates
                â†“
pymupdf_highlight_server.py processes PDF
                â†“
Returns: Text tokens with exact coordinates
```

#### **Step 3.2: Image Extraction**
```
gpt5VisionAnalyzer.ts â†’ extractPDFImages()
                â†“
HTTP POST â†’ localhost:5175/convert-to-images
                â†“
pymupdf_highlight_server.py converts PDF pages to PNG
                â†“
Returns: Base64 encoded images (300 DPI)
```

#### **Step 3.3: Create Chunks**
```
gpt5VisionAnalyzer.ts â†’ createDynamicChunks()
                â†“
Groups pages based on token budget (8000 tokens)
                â†“
Creates chunks with images + text
```

#### **Step 3.4: Vision Analysis (THE CRITICAL PART)**
```
For each chunk:
    gpt5VisionAnalyzer.ts â†’ processChunkWithVision()
                    â†“
    Creates prompt with:
    - Text content
    - Base64 images
    - Instructions to find issues
                    â†“
    HTTP POST â†’ api.openai.com/v1/chat/completions
                    â†“
    GPT-5 analyzes images
                    â†“
    Returns JSON with issues and coordinates
```

#### **Step 3.5: Parse & Validate Results**
```
gpt5VisionAnalyzer.ts â†’ parseVisionResponse()
                â†“
Validates coordinates exist
                â†“
Converts pixel coordinates â†’ PDF points (72 DPI)
                â†“
Filters invalid issues
```

### **Phase 4: Creating Highlights**

```
gpt5VisionAnalyzer.ts â†’ combineChunkResults()
                â†“
All issues combined into single array
                â†“
HTTP POST â†’ localhost:5175/highlight-pdf
                â†“
pymupdf_highlight_server.py â†’ highlight_pdf()
                â†“
For each issue:
    - Creates yellow rectangle at coordinates
    - Adds to PDF as annotation
                â†“
Returns: Modified PDF with highlights
```

### **Phase 5: Display Results**

```
Backend returns highlighted PDF
                â†“
CreditReportAnalyzerApp.tsx updates state
                â†“
Right panel shows highlighted PDF
                â†“
"Download Highlighted PDF" button appears
```

---

## ğŸ”´ WHERE THINGS ARE BREAKING

### **Problem 1: GPT-5 Finding Too Few Issues**
- **Location**: `gpt5VisionAnalyzer.ts` â†’ `createVisionAnalysisPrompt()`
- **Issue**: Prompt is too restrictive, only looking for missing data
- **File**: Lines 469-533

### **Problem 2: Coordinates Not Working**
- **Location**: `gpt5VisionAnalyzer.ts` â†’ `combineChunkResults()`
- **Issue**: Pixel to points conversion may be wrong
- **File**: Lines 579-597

### **Problem 3: Validation Too Strict**
- **Location**: `gpt5VisionAnalyzer.ts` â†’ Lines 599-606
- **Issue**: Rejecting valid issues due to coordinate validation

---

## ğŸ“ Key Files & Their Roles

### **Frontend Files:**
1. `src/components/generated/CreditReportAnalyzerApp.tsx`
   - Main UI component
   - Handles file upload
   - Triggers analysis
   - Displays results

2. `src/services/gpt5VisionAnalyzer.ts`
   - Orchestrates entire analysis
   - Calls PyMuPDF server
   - Calls GPT-5 API
   - Processes results

### **Backend Files:**
1. `pymupdf_highlight_server.py`
   - `/health` - Health check
   - `/convert-to-images` - PDF â†’ PNG conversion
   - `/extract-text-coordinates` - Text extraction
   - `/highlight-pdf` - Apply highlights

### **Test Scripts:**
1. `test-real-gpt5-vision.py` - Original test
2. `test-improved-gpt5-vision.py` - Multi-pass test
3. `test-iterative-gpt5-vision.py` - One issue type at a time

---

## ğŸ”„ API Call Sequence

```
1. Frontend â†’ PyMuPDF: Extract text (optional)
2. Frontend â†’ PyMuPDF: Convert to images
3. Frontend â†’ OpenAI: Analyze images with GPT-5
4. Frontend â†’ PyMuPDF: Apply highlights
5. Frontend displays result
```

---

## ğŸ› Current Issues & Solutions

### **Issue 1: Only 4 issues found**
**Cause**: GPT-5 prompt too restrictive
**Solution**: Broadened prompt in lines 473-533

### **Issue 2: Highlights not showing**
**Possible Causes**:
1. Coordinates are in wrong format
2. Validation rejecting valid issues
3. PyMuPDF not receiving correct data

### **Issue 3: Too many console logs**
**Cause**: Processing each page individually
**Solution**: Added summary logging

---

## ğŸ” How to Debug

1. **Check GPT-5 Response**:
   - Look for "GPT-5 Vision API response received" in console
   - Check if JSON contains coordinates

2. **Check Coordinate Format**:
   - Should be: `{x: number, y: number, width: number, height: number}`
   - Must be in PDF points (72 DPI), not pixels

3. **Check PyMuPDF Server**:
   - Look for `/highlight-pdf` requests
   - Check if returning 200 status

4. **Check Final Issues Array**:
   - Before sending to PyMuPDF
   - Must have valid coordinates for each issue

---

## ğŸ“ Quick Test

To test if highlighting works at all:
```python
python3 test-improved-gpt5-vision.py
```

This will create test outputs in `improved_test_outputs/` folder.

---

## ğŸ¯ Summary

The flow is:
1. **Upload PDF** â†’ Frontend
2. **Convert to images** â†’ PyMuPDF Server
3. **Analyze images** â†’ GPT-5 Vision API
4. **Get coordinates** â†’ From GPT-5 response
5. **Apply highlights** â†’ PyMuPDF Server
6. **Show result** â†’ Frontend

The break is likely at step 4 (not getting good coordinates) or step 5 (coordinate format wrong for PyMuPDF).