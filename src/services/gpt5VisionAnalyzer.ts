// GPT-5 Vision-Enhanced Credit Report Analyzer
// Combines text analysis with vision processing for complete issue detection

import { API_CONFIG } from '../config/api';
import { getOpenAIKey } from '../settings/openai';
import { globalCostTracker, CostTracker } from './costTracker';
import { serverHealthMonitor } from '../utils/serverHealthCheck';
import type {
  AnalysisResult,
  CreditIssue,
  PDFDocument,
  OpenAIResponse,
} from '../types/creditReport';

// OpenAI Message Types
interface ChatCompletionMessage {
  role: 'system' | 'user' | 'assistant';
  content: string | Array<{
    type: 'text' | 'image_url';
    text?: string;
    image_url?: {
      url: string;
      detail?: 'low' | 'high' | 'auto';
    };
  }>;
}

export interface VisionAnalysisChunk {
  chunkIndex: number;
  pageRange: { start: number; end: number };
  textContent: string;
  images: Array<{
    pageNumber: number;
    imageData: string;
    mimeType: string;
    width?: number;
    height?: number;
    dpi?: number;
  }>;
  contextSummary?: string;
}

export interface VisionAnalysisResult {
  issues: CreditIssue[];
  emptyPaymentCells: Array<{
    pageNumber: number;
    coordinates: { x: number; y: number; width: number; height: number };
    description: string;
    tableType: string;
  }>;
  contextSummary: string;
  costBreakdown: {
    inputTokens: number;
    outputTokens: number;
    totalCost: number;
  };
}

export class GPT5VisionAnalyzer {
  private apiKey: string;
  private baseUrl: string;
  private costTracker: CostTracker;
  private pageImageInfo: Map<number, { width: number; height: number; dpi: number }> = new Map();

  constructor() {
    this.apiKey = API_CONFIG.OPENAI_API_KEY;
    this.baseUrl = API_CONFIG.OPENAI_BASE_URL;
    this.costTracker = globalCostTracker;
  }

  /**
   * Analyze PDF with GPT-5 vision + text processing
   */
  async analyzeWithVision(
    pdfDocument: PDFDocument,
    pdfFile?: File,
    progressCallback?: (progress: string) => void
  ): Promise<AnalysisResult> {
    try {
      console.log('üéØ Starting GPT-5 Vision Analysis...');
      
      // Initialize cost tracking
      this.costTracker.initializeTracking(pdfDocument.totalPages);
      
      progressCallback?.('Extracting images from PDF...');
      
      // Step 1: Convert PDF to images
      let images: Array<{
        pageNumber: number;
        imageData: string;
        mimeType: string;
        width?: number;
        height?: number;
        dpi?: number;
      }> = [];
      if (pdfFile) {
        images = await this.extractPDFImages(pdfFile);
      } else {
        console.warn('No PDF file provided for image extraction, proceeding with text-only analysis');
      }
      
      progressCallback?.('Creating dynamic chunks...');
      
      // Step 2: Create dynamic chunks with token-aware budgeting
      const chunks = this.createDynamicChunks(pdfDocument, images);
      
      // Step 3: Process each chunk with vision analysis
      const allResults: VisionAnalysisResult[] = [];
      let contextSummary = '';
      
      for (let i = 0; i < chunks.length; i++) {
        const chunk = chunks[i];
        progressCallback?.(this.costTracker.getFormattedCostDisplay());
        
        console.log(`üìä Processing chunk ${i + 1}/${chunks.length} (Pages ${chunk.pageRange.start}-${chunk.pageRange.end})`);
        
        const chunkResult = await this.processChunkWithVision(chunk, contextSummary);
        allResults.push(chunkResult);
        
        // Update context for next chunk
        contextSummary = chunkResult.contextSummary;
      }
      
      progressCallback?.('Compiling final analysis...');
      
      // Step 4: Combine results from all chunks
      const finalResult = this.combineChunkResults(allResults, pdfDocument.totalPages);
      
      // Log final cost summary
      const costReport = this.costTracker.getFinalReport();
      console.log(`üí∞ Final Cost: $${costReport.totalCost.toFixed(3)} | Efficiency: ${(costReport.processingEfficiency * 100).toFixed(1)}%`);
      
      return finalResult;
      
    } catch (error) {
      console.error('‚ùå GPT-5 Vision Analysis Error:', error);
      const message = error instanceof Error ? error.message : String(error);
      const stack = error instanceof Error ? error.stack : undefined;
      const newError = new Error(`Failed to analyze credit report: ${message}`);
      if (stack) {
        newError.stack = `${newError.stack}\nCaused by:\n${stack}`;
      }
      throw newError;
    }
  }

  /**
   * Extract PDF pages as high-quality images
   */
  private async extractPDFImages(pdfFile: File): Promise<Array<{
    pageNumber: number;
    imageData: string;
    mimeType: string;
    width?: number;
    height?: number;
    dpi?: number;
  }>> {
    try {
      // Preflight health check before attempting conversion
      await serverHealthMonitor.ensureServerAvailable();
      const formData = new FormData();
      formData.append('pdf', pdfFile);
      formData.append('dpi', '300'); // High DPI for vision analysis
      formData.append('format', 'PNG');
      
      const response = await fetch(`${API_CONFIG.PYMUPDF_SERVER_URL}/convert-to-images`, {
        method: 'POST',
        mode: 'cors',
        credentials: 'omit',
        body: formData,
      });
      
      if (!response.ok) {
        throw new Error(`Image extraction failed: ${response.status}`);
      }
      
      const data = await response.json();
      
      // Runtime validation for data.images
      if (!data || !Array.isArray(data.images)) {
        console.error('Invalid response: missing or non-array images field', data);
        return [];
      }
      
      // Validate and filter images to ensure correct shape
      const images = data.images.filter((img: any) => {
        const isValid = img && 
          typeof img.pageNumber === 'number' &&
          typeof img.imageData === 'string' &&
          typeof img.mimeType === 'string';
        
        if (!isValid) {
          console.warn('Skipping invalid image entry:', img);
        }
        
        return isValid;
      }).map((img: any) => ({
        pageNumber: img.pageNumber,
        imageData: img.imageData,
        mimeType: img.mimeType,
        width: typeof img.width === 'number' ? img.width : undefined,
        height: typeof img.height === 'number' ? img.height : undefined,
        dpi: typeof img.dpi === 'number' ? img.dpi : undefined
      }));

      // Cache per-page image info for coordinate conversion
      this.pageImageInfo.clear();
      for (const img of images) {
        if (typeof img.pageNumber === 'number') {
          this.pageImageInfo.set(img.pageNumber, {
            width: Number(img.width) || 0,
            height: Number(img.height) || 0,
            dpi: Number(img.dpi) || 300
          });
        }
      }

      return images;
      
    } catch (error) {
      console.error('‚ùå PDF image extraction failed:', error);
      
      // Provide specific error based on the failure type
      let errorMessage = 'Failed to convert PDF to images: ';
      
      if (error instanceof Error) {
        if (error.message.includes('PyMuPDF server is not available')) {
          errorMessage = error.message; // Use the preflight check error
        } else if (error.message.includes('fetch')) {
          errorMessage += `Network error - PyMuPDF server at ${API_CONFIG.PYMUPDF_SERVER_URL} is not reachable. `;
          errorMessage += `Please run: python3 pymupdf_highlight_server.py`;
        } else if (error.message.includes('CORS')) {
          errorMessage += `CORS blocked - PyMuPDF server needs proper CORS headers. `;
          errorMessage += `Ensure Flask server has flask-cors installed and configured.`;
        } else {
          errorMessage += error.message;
        }
      } else {
        errorMessage += `PyMuPDF server error at ${API_CONFIG.PYMUPDF_SERVER_URL}`;
      }
      
      throw new Error(errorMessage);
    }
  }

  /**
   * Create smart chunks based on account boundaries and context preservation
   */
  private createSmartChunks(
    pdfDocument: PDFDocument, 
    images: Array<{pageNumber: number; imageData: string; mimeType: string}>
  ): VisionAnalysisChunk[] {
    const chunks: VisionAnalysisChunk[] = [];
    const pagesPerChunk = 4; // Target 4 pages per chunk to manage token limits
    
    for (let i = 0; i < pdfDocument.pages.length; i += pagesPerChunk) {
      const startPage = i;
      const endPage = Math.min(i + pagesPerChunk - 1, pdfDocument.pages.length - 1);
      
      // Get text content for this chunk
      const chunkPages = pdfDocument.pages.slice(startPage, endPage + 1);
      const textContent = chunkPages
        .map(page => `Page ${page.pageNumber}:\n${page.text}`)
        .join('\n\n');
      
      // Get corresponding images
      const chunkImages = images.filter(img => 
        img.pageNumber >= startPage + 1 && img.pageNumber <= endPage + 1
      );
      
      chunks.push({
        chunkIndex: chunks.length,
        pageRange: { start: startPage + 1, end: endPage + 1 },
        textContent,
        images: chunkImages
      });
    }
    
    console.log(`üìù Created ${chunks.length} smart chunks for processing`);
    return chunks;
  }

  /**
   * Create dynamic chunks that respect an approximate token budget.
   * Token estimate: text chars/4 + ~1200 tokens per high-detail page image.
   */
  private createDynamicChunks(
    pdfDocument: PDFDocument,
    images: Array<{ pageNumber: number; imageData: string; mimeType: string }>
  ): VisionAnalysisChunk[] {
    const targetTokens = 8000; // target per chunk
    const hardMaxTokens = 12000; // never exceed

    const numPages = pdfDocument.pages.length;
    const pageText = (i: number) => pdfDocument.pages[i].text || '';
    const pageTokens = (i: number) => Math.ceil(pageText(i).length / 4);
    const imageTokensPerPage = 1200; // conservative estimate

    const chunks: VisionAnalysisChunk[] = [];
    let start = 0;
    while (start < numPages) {
      let end = start;
      let sumTokens = 0;
      while (end < numPages) {
        const t = pageTokens(end);
        const hasImg = images.some(img => img.pageNumber === end + 1);
        const next = sumTokens + t + (hasImg ? imageTokensPerPage : 0);
        if (next > targetTokens && end > start) break;
        if (next > hardMaxTokens) break;
        sumTokens = next;
        end++;
      }

      const pages = pdfDocument.pages.slice(start, end);
      const textContent = pages.map(p => `Page ${p.pageNumber}:\n${p.text}`).join('\n\n');
      const chunkImages = images.filter(img => img.pageNumber >= start + 1 && img.pageNumber <= end);

      chunks.push({
        chunkIndex: chunks.length,
        pageRange: { start: start + 1, end },
        textContent,
        images: chunkImages
      });

      start = end;
    }

    console.log(`üìù Created ${chunks.length} dynamic chunks (budget ~${targetTokens} tok)`);
    return chunks;
  }

  /**
   * Process a single chunk with GPT-5 vision analysis
   */
  private async processChunkWithVision(
    chunk: VisionAnalysisChunk,
    previousContext: string
  ): Promise<VisionAnalysisResult> {
    // Interleave page labels with images to help the model attribute coordinates to correct pages
    const labeledImageContents = chunk.images.flatMap(img => {
      const w = img.width || 'unknown';
      const h = img.height || 'unknown';
      const dpi = img.dpi || 300;
      return [
        { type: 'text' as const, text: `The next image is page ${img.pageNumber}, ${w}x${h} pixels at ${dpi} DPI. Measure coordinates in PIXELS from the top-left corner.` },
        {
          type: 'image_url' as const,
          image_url: {
            url: `data:${img.mimeType};base64,${img.imageData}`,
            detail: 'high' as const
          }
        }
      ];
    });

    const messages: ChatCompletionMessage[] = [
      {
        role: 'system',
        content: `You are an expert credit report analyst with advanced vision capabilities. 
        
Analyze both TEXT and IMAGES to identify:
1. Credit report violations and issues
2. Missing payment information (empty cells in payment tables)
3. Incorrect payment information
4. Missing or truncated account numbers
5. Account name issues

For empty payment table cells, provide precise coordinates where the missing data should be highlighted.

Always respond with valid JSON only.`
      },
      {
        role: 'user',
        content: [
          { type: 'text', text: this.createVisionAnalysisPrompt(chunk, previousContext) },
          ...labeledImageContents
        ]
      }
    ];

    try {
      const response = await this.callGPT5Vision(messages);
      const parsedResult = this.parseVisionResponse(response);
      
      // Track API cost
      const estimatedInputTokens = chunk.textContent.length / 4 + chunk.images.length * 1000; // Rough estimate
      const estimatedOutputTokens = response.length / 4;
      const estimatedImageTokens = chunk.images.length * 1000;
      
      this.costTracker.trackAPICall(
        estimatedInputTokens,
        estimatedOutputTokens,
        estimatedImageTokens,
        'multimodal'
      );
      
      return parsedResult;
      
    } catch (error) {
      console.error('‚ùå Chunk processing failed:', error);
      throw error;
    }
  }

  /**
   * Create vision analysis prompt for GPT-5
   */
  private createVisionAnalysisPrompt(chunk: VisionAnalysisChunk, previousContext: string): string {
    return `You are an expert credit report analyst with advanced vision capabilities. Analyze pages ${chunk.pageRange.start}-${chunk.pageRange.end} of this credit report image carefully.

${previousContext ? `Previous context: ${previousContext}` : ''}

CRITICAL MISSION: Look for ACTUAL missing information in the credit report that would be legally significant:

1. MISSING OR TRUNCATED ACCOUNT NUMBERS:
   - Look for account numbers that show only xxxxxxxx1234 or similar patterns
   - Find completely missing account numbers where they should exist
   - Identify partial account numbers that are cut off or incomplete

2. EMPTY PAYMENT HISTORY CELLS:
   - Scan payment history tables for empty cells where payment data should exist
   - Look for missing payment amounts, dates, or statuses
   - Identify gaps in payment timelines

3. MISSING CREDITOR INFORMATION:
   - Find missing creditor names or company information
   - Look for blank fields where account names should appear
   - Identify incomplete contact information

4. INCOMPLETE BALANCE DATA:
   - Find missing balance amounts
   - Look for incomplete financial information
   - Identify missing limit or available credit data

5. MISSING DATES OR STATUS INFORMATION:
   - Find missing account opening dates
   - Look for missing payment due dates
   - Identify missing account status information

IMPORTANT: Only report issues you can actually SEE in the image. Provide precise pixel coordinates for each issue found.

For each coordinate, measure from the top-left corner of the page:
- x: pixels from left edge
- y: pixels from top edge  
- width: width of the issue area in pixels
- height: height of the issue area in pixels

TEXT CONTENT FOR REFERENCE:
${chunk.textContent}

Return ONLY valid JSON in this exact format:
{
  "issues": [
    {
      "id": "unique-id-here",
      "type": "critical|warning|attention|info",
      "category": "accuracy|FCRA_violation|collection|dispute|other",
      "description": "Precise description of what is missing or incomplete",
      "severity": "high|medium|low",
      "pageNumber": ${chunk.pageRange.start},
      "coordinates": {"x": 123, "y": 456, "width": 78, "height": 20},
      "anchorText": "exact text found at location or empty string if nothing there",
      "recommendedAction": "specific legal or corrective action needed",
      "mappingConfidence": 0.95,
      "mappingMethod": "vision_detection"
    }
  ],
  "emptyPaymentCells": [
    {
      "pageNumber": ${chunk.pageRange.start},
      "coordinates": {"x": 300, "y": 400, "width": 50, "height": 25},
      "description": "Specific payment data that is missing",
      "tableType": "Payment History|Balance|Scheduled Payment|Actual Payment"
    }
  ],
  "contextSummary": "Brief summary for next chunk analysis"
}

ONLY return the JSON. No other text.`;
  }

  /**
   * Call GPT-5 Vision API
   */
  private async callGPT5Vision(messages: ChatCompletionMessage[]): Promise<string> {
    const request = {
      model: 'gpt-5',
      messages,
      // GPT-5 specific params
      max_completion_tokens: 4000,
      reasoning_effort: 'low',
      temperature: 0.1
    };

    const apiKey = getOpenAIKey() || this.apiKey;
    if (!apiKey) {
      throw new Error('Missing OpenAI API key. Please add it in Settings or set OPENAI_API_KEY environment variable.');
    }

    console.log('üß† Making GPT-5 Vision API call...');
    
    const response = await fetch(`${this.baseUrl}/chat/completions`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(request),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('‚ùå GPT-5 Vision API error:', response.status, errorText);
      throw new Error(`GPT-5 Vision API error: ${response.status} ${errorText}`);
    }

    const data: OpenAIResponse = await response.json();
    const content = data.choices[0]?.message?.content || '';
    
    console.log('‚úÖ GPT-5 Vision API response received');
    console.log('üìä Response length:', content.length, 'characters');
    
    return content;
  }

  /**
   * Parse GPT-5 vision response
   */
  private parseVisionResponse(responseText: string): VisionAnalysisResult {
    let parsed: any;
    try {
      parsed = JSON.parse(responseText);
    } catch (error) {
      console.error('Failed to parse GPT-5 Vision response:', error);
      throw new Error('Invalid JSON from GPT-5 vision');
    }

    // Basic structure validation
    const issues = Array.isArray(parsed.issues) ? parsed.issues : [];
    const emptyPaymentCells = Array.isArray(parsed.emptyPaymentCells) ? parsed.emptyPaymentCells : [];

    return {
      issues,
      emptyPaymentCells,
      contextSummary: typeof parsed.contextSummary === 'string' ? parsed.contextSummary : '',
      costBreakdown: { inputTokens: 0, outputTokens: 0, totalCost: 0 }
    };
  }

  /**
   * Combine results from all processed chunks
   */
  private combineChunkResults(
    chunkResults: VisionAnalysisResult[],
    totalPages: number
  ): AnalysisResult {
    // Combine all issues from chunks
    const allIssues = chunkResults.flatMap(result => result.issues);
    
    // Add empty payment cell issues as credit issues
    const emptyPaymentIssues: CreditIssue[] = chunkResults.flatMap(result =>
      result.emptyPaymentCells.map(cell => ({
        id: `empty-payment-${crypto.randomUUID()}`,
        type: 'warning' as const,
        category: 'accuracy' as const,
        description: `Missing payment data: ${cell.description}`,
        severity: 'medium' as const,
        pageNumber: cell.pageNumber,
        coordinates: cell.coordinates,
        recommendedAction: 'Verify missing payment information with creditor',
        mappingConfidence: 1.0,
        mappingMethod: 'exact_match' as const
      }))
    );
    
    // Combine all issues
    const combinedIssues = [...allIssues, ...emptyPaymentIssues];

    // Convert coordinates from image pixels -> PDF points using per-page DPI
    const convert = (issue: any) => {
      const c = issue.coordinates;
      const info = this.pageImageInfo.get(issue.pageNumber);
      if (c && info && info.dpi) {
        const factor = 72 / info.dpi; // points per pixel
        issue.coordinates = {
          x: c.x * factor,
          y: c.y * factor,
          width: c.width * factor,
          height: c.height * factor,
        };
      }
      return issue;
    };

    for (let i = 0; i < combinedIssues.length; i++) {
      combinedIssues[i] = convert(combinedIssues[i]);
    }

    // Strict validation: all issues must have valid coordinates
    const invalid = combinedIssues.find(i => {
      const c = (i as any).coordinates;
      return !(c && [c.x, c.y, c.width, c.height].every((v: any) => typeof v === 'number' && !isNaN(v)));
    });
    if (invalid) {
      throw new Error(`Issue lacks valid coordinates (id=${invalid.id || 'unknown'})`);
    }
    
    // Count issues by type
    const issueCounts = {
      critical: combinedIssues.filter(i => i.type === 'critical').length,
      warning: combinedIssues.filter(i => i.type === 'warning').length,
      attention: combinedIssues.filter(i => i.type === 'attention').length,
      info: combinedIssues.filter(i => i.type === 'info').length,
    };
    
    return {
      totalIssues: combinedIssues.length,
      critical: issueCounts.critical,
      warning: issueCounts.warning,
      attention: issueCounts.attention,
      info: issueCounts.info,
      issues: combinedIssues,
      summary: `GPT-5 Vision analysis found ${combinedIssues.length} issues including ${emptyPaymentIssues.length} missing payment data entries`,
      confidence: 0.95, // High confidence with vision analysis
      analysisMetadata: {
        method: 'GPT-5 Vision + Text Analysis',
        contextPreserved: true,
        chunkingUsed: chunkResults.length > 1,
        fullDocumentAnalysis: true,
        chunksAnalyzed: chunkResults.length
      }
    };
  }
}
